{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70dc22bc-b28a-458e-9f3d-32a0cf7ca4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.11.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633a0e5e-22b8-46c8-8733-8e02f286e4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/\n",
      "Collecting gym-OT\n",
      "  Downloading https://test-files.pythonhosted.org/packages/ef/5d/0a1514ce28900403bb6eb41c9270b821969207e7d4c78be2460425627d01/gym_OT-1.0.10-py3-none-any.whl (5.4 kB)\n",
      "Installing collected packages: gym-OT\n",
      "Successfully installed gym-OT-1.0.10\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/jeroencvlier/utils.git\n",
    "!pip install -U -i https://test.pypi.org/simple/ gym-OT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06af01a-1399-475b-9bc3-794834ddb5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d56caf1-fa96-4f8f-90d5-3dfcd45e5e15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/marshmallow/__init__.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  __version_info__ = tuple(LooseVersion(__version__).version)\n",
      "2022-11-22 07:44:19,955\tINFO worker.py:1528 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.10</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.1.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.10', ray_version='2.1.0', ray_commit='be49bde7ee4f6adb3f8710aee0665c27f9f0bb62', address_info={'node_ip_address': '10.42.89.48', 'raylet_ip_address': '10.42.89.48', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-22_07-44-17_943480_61/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-22_07-44-17_943480_61/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-11-22_07-44-17_943480_61', 'metrics_export_port': 59477, 'gcs_address': '10.42.89.48:37235', 'address': '10.42.89.48:37235', 'dashboard_agent_listen_port': 52365, 'node_id': '71bd33533dcbeddbf658884592f11c2c40305e4ba1174c18bbaa7ca2'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym, os, glob\n",
    "from tqdm import tqdm\n",
    "from gym_OT.envs.OTGym_env import OTEnv_v0\n",
    "from ray import tune\n",
    "import gym_OT\n",
    "\n",
    "select_env = \"OT-v0\"\n",
    "tune.register_env(select_env, lambda: OTEnv_v0({}))\n",
    "\n",
    "import ray\n",
    "from ray.rllib.algorithms.dqn import DQN\n",
    "# from ray.rllib.algorithms.ppo import PPO\n",
    "# from ray.rllib.algorithms.sac import SAC\n",
    "\n",
    "from logger_ import custom_log_creator \n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True,num_cpus=8,num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9031345-ead0-4560-b3c0-6d94945cafb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd51e9d-2c05-4622-a150-72f17a214093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil,glob,os\n",
    "# [shutil.rmtree(x) for x in glob.glob('/notebooks/DQN_Checkpoint/*/')]\n",
    "# [os.remove(x) for x in glob.glob('/notebooks/DQN_Checkpoint/*.*')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd848c4-1035-453a-9cdd-d9382c6399ff",
   "metadata": {},
   "source": [
    "replay_buffer_config = {\n",
    "            \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n",
    "            # Specify prioritized replay by supplying a buffer type that supports\n",
    "            # prioritization, for example: MultiAgentPrioritizedReplayBuffer.\n",
    "            \"prioritized_replay\": DEPRECATED_VALUE,\n",
    "            # Size of the replay buffer. Note that if async_updates is set,\n",
    "            # then each worker will have a replay buffer of this size.\n",
    "            \"capacity\": 50000,\n",
    "            \"prioritized_replay_alpha\": 0.6,\n",
    "            # Beta parameter for sampling from prioritized replay buffer.\n",
    "            \"prioritized_replay_beta\": 0.4,\n",
    "            # Epsilon to add to the TD errors when updating priorities.\n",
    "            \"prioritized_replay_eps\": 1e-6,\n",
    "            # The number of continuous environment steps to replay at once. This may\n",
    "            # be set to greater than 1 to support recurrent models.\n",
    "            \"replay_sequence_length\": 1,\n",
    "            # Whether to compute priorities on workers.\n",
    "            \"worker_side_prioritization\": False,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2167b148-842d-40ff-a8b9-bcc7b081b95c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 07:44:36,966\tWARNING algorithm.py:2531 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Algorithm.train()`. Instead, you will have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.\n",
      "2022-11-22 07:44:36,968\tINFO simple_q.py:307 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "2022-11-22 07:44:36,971\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=509)\u001b[0m /usr/local/lib/python3.8/dist-packages/marshmallow/__init__.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=509)\u001b[0m   __version_info__ = tuple(LooseVersion(__version__).version)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=509)\u001b[0m mounted drive detected!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=509)\u001b[0m Loading Scalers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=504)\u001b[0m /usr/local/lib/python3.8/dist-packages/marshmallow/__init__.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=504)\u001b[0m   __version_info__ = tuple(LooseVersion(__version__).version)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=512)\u001b[0m /usr/local/lib/python3.8/dist-packages/marshmallow/__init__.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=512)\u001b[0m   __version_info__ = tuple(LooseVersion(__version__).version)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=505)\u001b[0m /usr/local/lib/python3.8/dist-packages/marshmallow/__init__.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=505)\u001b[0m   __version_info__ = tuple(LooseVersion(__version__).version)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=507)\u001b[0m /usr/local/lib/python3.8/dist-packages/marshmallow/__init__.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=507)\u001b[0m   __version_info__ = tuple(LooseVersion(__version__).version)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=511)\u001b[0m /usr/local/lib/python3.8/dist-packages/marshmallow/__init__.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=511)\u001b[0m   __version_info__ = tuple(LooseVersion(__version__).version)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=504)\u001b[0m mounted drive detected!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=504)\u001b[0m Loading Scalers\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=512)\u001b[0m mounted drive detected!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=512)\u001b[0m Loading Scalers\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=505)\u001b[0m mounted drive detected!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=505)\u001b[0m Loading Scalers\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=507)\u001b[0m mounted drive detected!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=507)\u001b[0m Loading Scalers\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=511)\u001b[0m mounted drive detected!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=511)\u001b[0m Loading Scalers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=504)\u001b[0m 2022-11-22 07:44:43,549\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=513)\u001b[0m /usr/local/lib/python3.8/dist-packages/marshmallow/__init__.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=513)\u001b[0m   __version_info__ = tuple(LooseVersion(__version__).version)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=513)\u001b[0m mounted drive detected!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=513)\u001b[0m Loading Scalers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 07:44:53,231\tWARNING deprecation.py:47 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "2022-11-22 07:44:53,234\tWARNING algorithm.py:2531 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Algorithm.train()`. Instead, you will have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=747)\u001b[0m /usr/local/lib/python3.8/dist-packages/marshmallow/__init__.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=747)\u001b[0m   __version_info__ = tuple(LooseVersion(__version__).version)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=747)\u001b[0m mounted drive detected!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=747)\u001b[0m Loading Scalers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=747)\u001b[0m 2022-11-22 07:44:57,940\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "2022-11-22 07:45:01,057\tINFO trainable.py:164 -- Trainable.setup took 24.091 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring checkpoint:  /notebooks/DQN_Checkpoint/checkpoint_000960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:1688: DeprecationWarning: invalid escape sequence \\|\n",
      "  \"\"\"Adds a new policy to this Algorithm.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/notebooks/DQN_Checkpoint/checkpoint_*\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRestoring checkpoint: \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mmax\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/notebooks/DQN_Checkpoint/checkpoint_*\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m---> 25\u001b[0m     \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/notebooks/DQN_Checkpoint/checkpoint_*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500000\u001b[39m)):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/tune/trainable/trainable.py:759\u001b[0m, in \u001b[0;36mTrainable.restore\u001b[0;34m(self, checkpoint_path, checkpoint_node_ip, fallback_to_latest)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_episodes_total \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisodes_total\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    758\u001b[0m \u001b[38;5;66;03m# Actually load checkpoint\u001b[39;00m\n\u001b[0;32m--> 759\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_load\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timesteps_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:1986\u001b[0m, in \u001b[0;36mAlgorithm.load_checkpoint\u001b[0;34m(self, checkpoint)\u001b[0m\n\u001b[1;32m   1983\u001b[0m \u001b[38;5;66;03m# Checkpoint is a checkpoint-as-dict -> Restore state from it as-is.\u001b[39;00m\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1985\u001b[0m     checkpoint_data \u001b[38;5;241m=\u001b[39m checkpoint\n\u001b[0;32m-> 1986\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__setstate__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:2757\u001b[0m, in \u001b[0;36mAlgorithm.__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   2751\u001b[0m \u001b[38;5;66;03m# TODO (sven): Validate that our config and the config in state are compatible.\u001b[39;00m\n\u001b[1;32m   2752\u001b[0m \u001b[38;5;66;03m#  For example, the model architectures may differ.\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \u001b[38;5;66;03m#  Also, what should the behavior be if e.g. some training parameter\u001b[39;00m\n\u001b[1;32m   2754\u001b[0m \u001b[38;5;66;03m#  (e.g. lr) changed?\u001b[39;00m\n\u001b[1;32m   2756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkers\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[0;32m-> 2757\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2758\u001b[0m     remote_state \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   2759\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39mremote_workers():\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py:1613\u001b[0m, in \u001b[0;36mRolloutWorker.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   1605\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_policy(\n\u001b[1;32m   1606\u001b[0m                 policy_id\u001b[38;5;241m=\u001b[39mpid,\n\u001b[1;32m   1607\u001b[0m                 policy_cls\u001b[38;5;241m=\u001b[39mpolicy_spec\u001b[38;5;241m.\u001b[39mpolicy_class,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1610\u001b[0m                 config\u001b[38;5;241m=\u001b[39mpolicy_spec\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m   1611\u001b[0m             )\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_map:\n\u001b[0;32m-> 1613\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;66;03m# Also restore mapping fn and which policies to train.\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_mapping_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/policy/torch_policy.py:751\u001b[0m, in \u001b[0;36mTorchPolicy.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    749\u001b[0m optimizer_vars \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_optimizer_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_vars:\n\u001b[0;32m--> 751\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_vars) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers)\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers, optimizer_vars):\n\u001b[1;32m    753\u001b[0m         optim_state_dict \u001b[38;5;241m=\u001b[39m convert_to_torch_tensor(s, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configure the algorithm.\n",
    "config = {\n",
    "    \"num_workers\": 7,\n",
    "    \"num_gpus_per_worker\":0.125,\n",
    "    \"num_envs_per_worker\":1,\n",
    "    \"num_gpus\": 1,\n",
    "    \"framework\": \"torch\",\n",
    "    \"model\": {\"fcnet_hiddens\": [800, 800, 400],\n",
    "              \"fcnet_activation\": \"relu\"},\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    \"evaluation_config\": {\"render_env\": False,\n",
    "    },\n",
    "    \"replay_buffer_config\":{\"capacity\": 500000}\n",
    "    \n",
    "}\n",
    "\n",
    "algo = DQN(env=OTEnv_v0,config=config,logger_creator=custom_log_creator(\"/notebooks/ray_results\", 'DQN'))\n",
    "\n",
    "# algo = PPO(env=OTEnv_v0,config=config,logger_creator=custom_log_creator(\"/notebooks/ray_results\", 'PPO'))\n",
    "\n",
    "# algo = SAC(env=OTEnv_v0,config=config,logger_creator=custom_log_creator(\"/notebooks/ray_results\", 'SAC'))\n",
    "\n",
    "if len(glob.glob('/notebooks/DQN_Checkpoint/checkpoint_*'))>1:\n",
    "    print('Restoring checkpoint: ',max(glob.glob('/notebooks/DQN_Checkpoint/checkpoint_*')))\n",
    "    algo.restore('/notebooks/'+sorted(glob.glob('checkpoint_directory/*'))[-2])\n",
    "\n",
    "for _ in tqdm(range(500000)):\n",
    "    for _ in range(20):\n",
    "        algo.train()\n",
    "    checkpoint = algo.save(\"/notebooks/DQN_Checkpoint\")\n",
    "    [shutil.rmtree(x) for x in  sorted(glob.glob('/notebooks/DQN_Checkpoint/*/'))[:-10]]\n",
    "\n",
    "algo.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "543e243d-d0de-41cf-a649-f50b7627cbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/notebooks/DQN_Checkpoint/checkpoint_000940',\n",
       " '/notebooks/DQN_Checkpoint/checkpoint_000960',\n",
       " '/notebooks/DQN_Checkpoint/checkpoint_000900',\n",
       " '/notebooks/DQN_Checkpoint/checkpoint_000920',\n",
       " '/notebooks/DQN_Checkpoint/checkpoint_000880']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('/notebooks/DQN_Checkpoint/checkpoint_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8c19dbe-0c7c-4f52-bb01-76469e272f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint_directory/checkpoint_000920'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(glob.glob('checkpoint_directory/*'))[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d5af8acd-28d6-4069-8b8b-24f1b3ffa4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 08:55:13,682\tINFO trainable.py:766 -- Restored on 10.42.89.48 from checkpoint: /notebooks/checkpoint_directory/checkpoint_000920\n",
      "2022-11-22 08:55:13,683\tINFO trainable.py:775 -- Current state after restoring: {'_iteration': 920, '_timesteps_total': None, '_time_total': 4100.400064945221, '_episodes_total': 11736}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "504444ee-2611-48f2-920c-1216a8fe9cbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "save_to_object() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_to_object\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint_directory/checkpoint_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: save_to_object() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "algo.save_to_object(\"checkpoint_directory/checkpoint_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b22dc367-040f-4c93-a216-d69a79dfa357",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_from_object\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoint_directory/checkpoint_1/policy_state.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/tune/trainable/trainable.py:782\u001b[0m, in \u001b[0;36mTrainable.restore_from_object\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrestore_from_object\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;124;03m\"\"\"Restores training state from a checkpoint object.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m    These checkpoints are returned from calls to save_to_object().\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 782\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mCheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m checkpoint\u001b[38;5;241m.\u001b[39mas_directory() \u001b[38;5;28;01mas\u001b[39;00m checkpoint_path:\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore(checkpoint_path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/air/checkpoint.py:277\u001b[0m, in \u001b[0;36mCheckpoint.from_bytes\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_bytes\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data: \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;124;03m\"\"\"Create a checkpoint from the given byte string.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        Checkpoint: checkpoint object.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     bytes_data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bytes_data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    279\u001b[0m         data_dict \u001b[38;5;241m=\u001b[39m bytes_data\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "algo.restore_from_object('checkpoint_directory/checkpoint_1/policy_state.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "085f4b72-1072-470d-bdb1-1695e1fdca29",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDQN_Checkpoint/checkpoint_000920/rllib_checkpoint.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/tune/trainable/trainable.py:759\u001b[0m, in \u001b[0;36mTrainable.restore\u001b[0;34m(self, checkpoint_path, checkpoint_node_ip, fallback_to_latest)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_episodes_total \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisodes_total\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    758\u001b[0m \u001b[38;5;66;03m# Actually load checkpoint\u001b[39;00m\n\u001b[0;32m--> 759\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_load\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timesteps_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:1986\u001b[0m, in \u001b[0;36mAlgorithm.load_checkpoint\u001b[0;34m(self, checkpoint)\u001b[0m\n\u001b[1;32m   1983\u001b[0m \u001b[38;5;66;03m# Checkpoint is a checkpoint-as-dict -> Restore state from it as-is.\u001b[39;00m\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1985\u001b[0m     checkpoint_data \u001b[38;5;241m=\u001b[39m checkpoint\n\u001b[0;32m-> 1986\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__setstate__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/algorithms/algorithm.py:2757\u001b[0m, in \u001b[0;36mAlgorithm.__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   2751\u001b[0m \u001b[38;5;66;03m# TODO (sven): Validate that our config and the config in state are compatible.\u001b[39;00m\n\u001b[1;32m   2752\u001b[0m \u001b[38;5;66;03m#  For example, the model architectures may differ.\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \u001b[38;5;66;03m#  Also, what should the behavior be if e.g. some training parameter\u001b[39;00m\n\u001b[1;32m   2754\u001b[0m \u001b[38;5;66;03m#  (e.g. lr) changed?\u001b[39;00m\n\u001b[1;32m   2756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkers\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[0;32m-> 2757\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2758\u001b[0m     remote_state \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   2759\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39mremote_workers():\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/evaluation/rollout_worker.py:1613\u001b[0m, in \u001b[0;36mRolloutWorker.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   1605\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_policy(\n\u001b[1;32m   1606\u001b[0m                 policy_id\u001b[38;5;241m=\u001b[39mpid,\n\u001b[1;32m   1607\u001b[0m                 policy_cls\u001b[38;5;241m=\u001b[39mpolicy_spec\u001b[38;5;241m.\u001b[39mpolicy_class,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1610\u001b[0m                 config\u001b[38;5;241m=\u001b[39mpolicy_spec\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m   1611\u001b[0m             )\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_map:\n\u001b[0;32m-> 1613\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;66;03m# Also restore mapping fn and which policies to train.\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_mapping_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/rllib/policy/torch_policy.py:751\u001b[0m, in \u001b[0;36mTorchPolicy.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    749\u001b[0m optimizer_vars \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_optimizer_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_vars:\n\u001b[0;32m--> 751\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_vars) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers)\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers, optimizer_vars):\n\u001b[1;32m    753\u001b[0m         optim_state_dict \u001b[38;5;241m=\u001b[39m convert_to_torch_tensor(s, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "algo.restore('DQN_Checkpoint/checkpoint_000920/rllib_checkpoint.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d5d13-8161-4017-bdcb-37e25dba83d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = DQNConfig()\n",
    "\n",
    "# config = config.resources(num_gpus=1,num_gpus_per_worker = 0.125) \n",
    "# config = config.rollouts(num_rollout_workers=4,num_envs_per_worker=2)\n",
    "# config = config.environment(OTEnv_v0)\n",
    "# config = config.framework(\"torch\")\n",
    "\n",
    "# # network\n",
    "# config.model['fcnet_hiddens'] = ['256','256']\n",
    "# config.model['fcnet_activation'] = \"relu\"\n",
    "\n",
    "# # tunning\n",
    "# config = config.training(lr=tune.grid_search([0.005, 0.003, 0.001, 0.0001]))\n",
    "\n",
    "# # eval\n",
    "# config.evaluation_num_workers = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
